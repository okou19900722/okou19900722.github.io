{"pageProps":{"categories":["releases","guides","news"],"post":{"meta":{"title":"Centralized logging for Vert.x applications using the ELK stack","category":"guides","authors":[{"name":"Ricardo Hernandez","github_id":"ricardohmon"}],"summary":"This post entry describes a solution to achieve centralized logging of Vert.x applications using the ELK stack (Logstash, Elasticsearch, and Kibana)."},"date":"2016-09-08","slug":"centralized-logging-for-vert-x-applications-using-the-elk-stack","readingTime":{"text":"11 min read","minutes":10.45,"time":627000,"words":2090},"content":{"compiledSource":"\"use strict\";\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar layoutProps = {};\nvar MDXLayout = \"wrapper\";\n\nfunction MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"This post entry de\\xADscribes a so\\xADlu\\xADtion to achieve cen\\xADtral\\xADized log\\xADging of Vert.x ap\\xADpli\\xADca\\xADtions using the \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.elastic.co/webinars/introduction-elk-stack\"\n  }), \"ELK stack\"), \", a set of tools in\\xADclud\\xADing Logstash, Elas\\xADtic\\xADsearch, and Kibana that are well known to work to\\xADgether seam\\xADlessly.\"), mdx(\"h2\", {\n    \"id\": \"preamble\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#preamble\"\n  })), \"Preamble\"), mdx(\"p\", null, \"This post was writ\\xADten in con\\xADtext of the project ti\\xADtled \\u201C\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://summerofcode.withgoogle.com/projects/#4858492141699072\"\n  }), \"De\\xADvOps tool\\xADing for Vert.x ap\\xADpli\\xADca\\xADtions\"), \"\\u201D, one of the Vert.x projects tak\\xADing place dur\\xADing the 2016 edi\\xADtion of \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://summerofcode.withgoogle.com/about/\"\n  }), \"Google Sum\\xADmer of Code\"), \", a pro\\xADgram that aims to bring to\\xADgether stu\\xADdents with open source or\\xADga\\xADni\\xADza\\xADtions, in order to help them to gain ex\\xADpo\\xADsure to soft\\xADware de\\xADvel\\xADop\\xADment prac\\xADtices and real-\\u200Bworld chal\\xADlenges.\"), mdx(\"h2\", {\n    \"id\": \"introduction\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#introduction\"\n  })), \"Introduction\"), mdx(\"p\", null, \"Cen\\xADtral\\xADized log\\xADging is an im\\xADpor\\xADtant topic while build\\xADing a Mi\\xADcroser\\xADvices ar\\xADchi\\xADtec\\xADture and it is a step for\\xADward to adopt\\xADing the De\\xADvOps cul\\xADture. Hav\\xADing an over\\xADall so\\xADlu\\xADtion par\\xADti\\xADtioned into a set of ser\\xADvices dis\\xADtrib\\xADuted across the In\\xADter\\xADnet can rep\\xADre\\xADsent a chal\\xADlenge when try\\xADing to mon\\xADi\\xADtor the log out\\xADput of each of them, hence, a tool that helps to ac\\xADcom\\xADplish this re\\xADsults very help\\xADful.\"), mdx(\"h2\", {\n    \"id\": \"overview\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#overview\"\n  })), \"Overview\"), mdx(\"p\", null, \"As shown in the di\\xADa\\xADgram below, the gen\\xADeral cen\\xADtral\\xADized log\\xADging so\\xADlu\\xADtion com\\xADprises two main el\\xADe\\xADments: the ap\\xADpli\\xADca\\xADtion server, which runs our Vert.x ap\\xADpli\\xADca\\xADtion; and a sep\\xADa\\xADrate server, host\\xADing the ELK stack. Both el\\xADe\\xADments are linked by File\\xADbeat, a highly con\\xADfig\\xADurable tool ca\\xADpa\\xADble of ship\\xADping our ap\\xADpli\\xADca\\xADtion logs to the Logstash in\\xADstance, i.e., our gate\\xADway to the ELK stack.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/images/blog/centralized-logging-using-elk/elk-overview.svg\",\n    \"alt\": \"Overview of centralized logging with ELK\"\n  }))), mdx(\"h2\", {\n    \"id\": \"app-logging-configuration\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#app-logging-configuration\"\n  })), \"App logging configuration\"), mdx(\"p\", null, \"The ap\\xADproach de\\xADscribed here is based on a File\\xADbeat + Logstash con\\xADfig\\xADu\\xADra\\xADtion, that means first we need to make sure our app logs to a file, whose records will be shipped to Logstash by File\\xADbeat. Luck\\xADily, Vert.x pro\\xADvides the means to \", mdx(Link, {\n    href: \"/docs/vertx-core/java/#_logging\",\n    passHref: true,\n    mdxType: \"Link\"\n  }, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"\"\n  }), \"con\\xADfig\\xADure\")), \" al\\xADter\\xADna\\xADtive log\\xADging frame\\xADworks (e.g., Log4j, Log4j2 and SLF4J) be\\xADsides the de\\xADfault JUL log\\xADging. How\\xADever, we can use File\\xADbeat in\\xADde\\xADpen\\xADdently of the log\\xADging frame\\xADwork cho\\xADsen.\"), mdx(\"h3\", {\n    \"id\": \"log4j-logging\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#log4j-logging\"\n  })), \"Log4j Logging\"), mdx(\"p\", null, \"The demo that ac\\xADcom\\xADpa\\xADnies this post re\\xADlies on Log4j2 as the log\\xADging frame\\xADwork. We in\\xADstructed Vert.x to use this frame\\xADwork fol\\xADlow\\xADing the \", mdx(Link, {\n    href: \"/docs/vertx-core/java/#_logging\",\n    passHref: true,\n    mdxType: \"Link\"\n  }, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"\"\n  }), \"guide\\xADlines\")), \" and we made sure our log\\xADging calls are made asyn\\xADchro\\xADnous, since we don\\u2019t want them to block our ap\\xADpli\\xADca\\xADtion. For this pur\\xADpose, we opted for the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"AsyncAppender\"), \" and this was in\\xADcluded in the Log4J con\\xADfig\\xADu\\xADra\\xADtion to\\xADgether with the log out\\xADput for\\xADmat de\\xADscribed in a XML con\\xADfig\\xADu\\xADra\\xADtion avail\\xADable in the ap\\xADpli\\xADca\\xADtion\\u2019s \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Re\\xADsource\"), \" folder.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-xml\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Configuration\"), \">\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Appenders\"), \">\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"RollingFile\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"name\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"vertx_logs\\\"\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"append\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"true\\\"\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"fileName\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/var/log/vertx.log\\\"\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"filePattern\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/var/log/vertx/$${date:yyyy-MM}/vertx-%d{MM-dd-yyyy}-%i.log.gz\\\"\"), \">\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"PatternLayout\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"pattern\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"%d{ISO8601} %-5p %c:%L - %m%n\\\"\"), \" />\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"RollingFile\"), \">\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Async\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"name\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"vertx_async\\\"\"), \">\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"AppenderRef\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"ref\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"vertx_logs\\\"\"), \"/>\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Async\"), \">\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Appenders\"), \">\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Loggers\"), \">\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Root\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"level\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"DEBUG\\\"\"), \">\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"AppenderRef\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"ref\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"vertx_async\\\"\"), \" />\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Root\"), \">\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Loggers\"), \">\"), \"\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Configuration\"), \">\"), \"\\n\")), mdx(\"h3\", {\n    \"id\": \"filebeat-configuration\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#filebeat-configuration\"\n  })), \"Filebeat configuration\"), mdx(\"p\", null, \"Now that we have con\\xADfig\\xADured the log out\\xADput of our Vert.x ap\\xADpli\\xADca\\xADtion to be stored in the file sys\\xADtem, we del\\xADe\\xADgate to File\\xADbeat the task of for\\xADward\\xADing the logs to the Logstash in\\xADstance. File\\xADbeat can be con\\xADfig\\xADured through a YAML file con\\xADtain\\xADing the logs out\\xADput lo\\xADca\\xADtion and the pat\\xADtern to in\\xADter\\xADpret mul\\xADti\\xADline logs (i.e., stack traces). Also, the Logstash out\\xADput plug\\xADin is con\\xADfig\\xADured with the host lo\\xADca\\xADtion and a se\\xADcure con\\xADnec\\xADtion is en\\xADforced using the cer\\xADtifi\\xADcate from the ma\\xADchine host\\xADing Logstash. We set the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"document_type\"), \" to the type of in\\xADstance that this log be\\xADlongs to, which could later help us while in\\xADdex\\xADing our logs in\\xADside Elas\\xADtic\\xADsearch.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-yaml\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"filebeat:\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"prospectors:\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-bullet\"\n  }), \"-\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"document_type:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"trader_dashboard\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"paths:\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-bullet\"\n  }), \"-\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"/var/log/vertx.log\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"multiline:\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"pattern:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"^[0-9]+\\\"\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"negate:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"match:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"after\"), \"\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"output:\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"logstash:\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"enabled:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"hosts:\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-bullet\"\n  }), \"-\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"elk:5044\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"timeout:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-number\"\n  }), \"15\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"tls:\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"insecure:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"false\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"certificate_authoritites:\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-bullet\"\n  }), \"-\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"/etc/pki/tls/certs/logstash-beats.crt\"), \"\\n\")), mdx(\"h2\", {\n    \"id\": \"elk-configuration\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#elk-configuration\"\n  })), \"ELK configuration\"), mdx(\"p\", null, \"To take fully ad\\xADvan\\xADtage of the ELK stack with re\\xADspect to Vert.x and our app logs, we need to con\\xADfig\\xADure each of its in\\xADdi\\xADvid\\xADual com\\xADpo\\xADnents, namely Logstash, Elas\\xADtic\\xADsearch and Kibana.\"), mdx(\"h3\", {\n    \"id\": \"logstash\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#logstash\"\n  })), \"Logstash\"), mdx(\"p\", null, \"Logstash is the com\\xADpo\\xADnent within the ELK stack that is in charge of ag\\xADgre\\xADgat\\xADing the logs from each of the sources and for\\xADward\\xADing them to the Elas\\xADtic\\xADsearch in\\xADstance.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Con\\xADfig\\xADur\\xADing Logstash is straight\\xADfor\\xADward with the help of the spe\\xADcific input and out\\xADput plu\\xADg\\xADins for Beats and Elas\\xADtic\\xADsearch, re\\xADspec\\xADtively.\\nIn the pre\\xADvi\\xADous sec\\xADtion we men\\xADtioned that File\\xADbeat could be eas\\xADily cou\\xADpled with Logstash. Now, we see that this can be done by just spec\\xADi\\xADfy\\xADing \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Beat\"), \" as the input plug\\xADin and set the pa\\xADra\\xADme\\xADters needed to be reached by our ship\\xADpers (lis\\xADten\\xADing port, ssl key and cer\\xADtifi\\xADcate lo\\xADca\\xADtion).\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-bash\"\n  }), \"input {\\n  beats {\\n    port => 5044\\n    ssl => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \"\\n    ssl_certificate => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/etc/pki/tls/certs/logstash-beats.crt\\\"\"), \"\\n    ssl_key => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/etc/pki/tls/private/logstash-beats.key\\\"\"), \"\\n  }\\n}\\n\")), mdx(\"p\", null, \"Now that we are ready to re\\xADceive logs from the app, we can use Logstash fil\\xADter\\xADing ca\\xADpa\\xADbil\\xADi\\xADties to spec\\xADify the for\\xADmat of our logs and ex\\xADtract the fields so they can be in\\xADdexed more ef\\xADfi\\xADciently by Elas\\xADtic\\xADsearch.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"grok\"), \" fil\\xADter\\xADing plug\\xADin comes handy in this sit\\xADu\\xADa\\xADtion. This plug\\xADin al\\xADlows to de\\xADclare the logs for\\xADmat using pre\\xADde\\xADfined and cus\\xADtomized pat\\xADterns based in reg\\xADu\\xADlar ex\\xADpres\\xADsions al\\xADlow\\xADing to de\\xADclare new fields from the in\\xADfor\\xADma\\xADtion ex\\xADtracted from each log line. In the fol\\xADlow\\xADing block, we in\\xADstruct Logstash to rec\\xADog\\xADnize our Log4j pat\\xADtern in\\xADside a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"message\"), \" field, which con\\xADtains the log mes\\xADsage shipped by File\\xADbeat. After that, the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"date\"), \" fil\\xADter\\xADing plug\\xADin parses the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"timestamp\"), \" field ex\\xADtracted in the pre\\xADvi\\xADous step and re\\xADplaces it for the one set by File\\xADbeat after read\\xADing the log out\\xADput file.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-bash\"\n  }), \"filter {\\n  grok {\\n    break_on_match => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"false\"), \"\\n    match =>  [ \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"message\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"%{LOG4J}\\\"\"), \"]\\n  }\\n  date{\\n    match => [ \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"timestamp_string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"ISO8601\\\"\"), \"]\\n    remove_field => [ \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"timestamp_string\\\"\"), \" ]\\n  }\\n}\\n\")), mdx(\"p\", null, \"The Log4j pat\\xADtern is not in\\xADcluded within the Logstash con\\xADfig\\xADu\\xADra\\xADtion, how\\xADever, we can spec\\xADify it using pre\\xADde\\xADfined data for\\xADmats shipped with Logstash and adapt it to the spe\\xADcific log for\\xADmats re\\xADquired in our ap\\xADpli\\xADca\\xADtion, as shown next.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-ruby\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-comment\"\n  }), \"# Pattern to match our Log4j format\"), \"\\nSPACING (?\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-symbol\"\n  }), \":\"), \"[\\\\s]+)\\nLOGGER (?\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-symbol\"\n  }), \":\"), \"[a-zA-Z$_][a-zA-Z$_0-\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-number\"\n  }), \"9\"), \"]*\\\\.)*[a-zA-Z$_][a-zA-Z$_0-\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-number\"\n  }), \"9\"), \"]*\\nLINE \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{INT}\"), \"?\\nLOG4J \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{TIMESTAMP_ISO8601:timestamp_string}\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{LOGLEVEL:log_level}\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{SPACING}\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{LOGGER:logger_name}\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-symbol\"\n  }), \":\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{LINE:loc_line}\")), \" - \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{JAVALOGMESSAGE:log_message}\"), \"\\n\")), mdx(\"p\", null, \"Fi\\xADnally, we take a look at Logstash\\u2019s out\\xADput con\\xADfig\\xADu\\xADra\\xADtion. This sim\\xADply points to our elas\\xADtic\\xADsearch in\\xADstance, in\\xADstructs it to pro\\xADvide a list of all clus\\xADter nodes (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"sniffing\"), \"), de\\xADfines the name pat\\xADtern for our in\\xADdices, as\\xADsigns the doc\\xADu\\xADment type ac\\xADcord\\xADing to the meta\\xADdata com\\xADing from File\\xADbeat, and al\\xADlows to de\\xADfine a cus\\xADtom index tem\\xADplate for our data.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-puppet\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-keyword\"\n  }), \"output\"), \" {\\n  elasticsearch {\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"hosts\"), \" => [\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"localhost\\\"\"), \"]\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"sniffing\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-keyword\"\n  }), \"true\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"manage_template\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-keyword\"\n  }), \"true\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"index\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"%{[@metadata][beat]}-%{+YYYY.MM.dd}\\\"\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"document_type\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"%{[@metadata][type]}\\\"\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"template\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/etc/filebeat/vertx_app_filebeat.json\\\"\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"template_overwrite\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-keyword\"\n  }), \"true\"), \"\\n  }\\n}\\n\")), mdx(\"h3\", {\n    \"id\": \"elasticsearch\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#elasticsearch\"\n  })), \"Elasticsearch\"), mdx(\"p\", null, \"Elas\\xADtic\\xADsearch is the cen\\xADtral com\\xADpo\\xADnent that en\\xADables the ef\\xADfi\\xADcient in\\xADdex\\xADing and real-\\u200Btime search ca\\xADpa\\xADbil\\xADi\\xADties of the stack. To take the most ad\\xADvan\\xADtage of Elas\\xADtic\\xADsearch, we can pro\\xADvide an in\\xADdex\\xADing tem\\xADplate of our in\\xADcom\\xADing logs, which can help to op\\xADti\\xADmize the data stor\\xADage and match the queries is\\xADsued by Kibana at a later point.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"In the ex\\xADam\\xADple below, we see an index tem\\xADplate that would be ap\\xADplied to any index match\\xADing the pat\\xADtern \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"filebeat-*\"), \". Ad\\xADdi\\xADtion\\xADally, we de\\xADclare our new log fields \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"type\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"host\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"log_level\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"logger_name\"), \", and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"log_message\"), \", which are set as \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"not_analyzed\"), \" ex\\xADcept for the last two that are set as \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"analyzed\"), \" al\\xADlow\\xADing to per\\xADform queries based on reg\\xADu\\xADlar ex\\xADpres\\xADsions and not re\\xADstricted to query the full text.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-json\"\n  }), \"{\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"mappings\\\"\"), \": {\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"_default_\\\"\"), \": {\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"_all\\\"\"), \": {\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"enabled\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \",\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"norms\\\"\"), \": {\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"enabled\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"false\"), \"\\n        }\\n      },\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"dynamic_templates\\\"\"), \": [\\n        {\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"template1\\\"\"), \": {\\n            \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"mapping\\\"\"), \": {\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"doc_values\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \",\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"ignore_above\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-number\"\n  }), \"1024\"), \",\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"not_analyzed\\\"\"), \",\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"{dynamic_type}\\\"\"), \"\\n            },\\n            \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"match\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"*\\\"\"), \"\\n          }\\n        }\\n      ],\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"properties\\\"\"), \": {\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"@timestamp\\\"\"), \": {\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"date\\\"\"), \"\\n        },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"offset\\\"\"), \": {\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"long\\\"\"), \",\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"doc_values\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"true\\\"\"), \"\\n        },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"not_analyzed\\\"\"), \" },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"host\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"not_analyzed\\\"\"), \" },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"log_level\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"not_analyzed\\\"\"), \" },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"logger_name\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"analyzed\\\"\"), \" },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"log_message\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"analyzed\\\"\"), \" }\\n      }\\n    }\\n  },\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"settings\\\"\"), \": {\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index.refresh_interval\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"5s\\\"\"), \"\\n  },\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"template\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"filebeat-*\\\"\"), \"\\n}\\n\")), mdx(\"h3\", {\n    \"id\": \"kibana\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#kibana\"\n  })), \"Kibana\"), mdx(\"p\", null, \"Al\\xADthough we could fetch all our logs from Elas\\xADtic\\xADsearch through its API, Kibana is a pow\\xADer\\xADful tool that al\\xADlows a more friendly query and vi\\xADsu\\xADal\\xADiza\\xADtion.\\nBe\\xADsides the op\\xADtion to query our data through the avail\\xADable in\\xADdexed field names and search boxes al\\xADlow\\xADing typ\\xADing spe\\xADcific queries, Kibana al\\xADlows cre\\xADat\\xADing our own \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Vi\\xADsu\\xADal\\xADiza\\xADtions\"), \" and \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Dash\\xADboards\"), \". Com\\xADbined, they rep\\xADre\\xADsent a pow\\xADer\\xADful way to dis\\xADplay data and gain in\\xADsight in a cus\\xADtomized man\\xADner.\\nThe ac\\xADcom\\xADpa\\xADnied demo ships with a cou\\xADple of sam\\xADple dash\\xADboards and vi\\xADsu\\xADal\\xADiza\\xADtions that take ad\\xADvan\\xADtage of the log fields that we spec\\xADi\\xADfied in our index tem\\xADplate and throw valu\\xADable in\\xADsight. This in\\xADcludes: vi\\xADsu\\xADal\\xADiz\\xADing the num\\xADber of log mes\\xADsages re\\xADceived by ELK, ob\\xADserve the pro\\xADpor\\xADtion of mes\\xADsages that each log source pro\\xADduces, and di\\xADrectly find out the sources of error logs.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/images/blog/centralized-logging-using-elk/kibana-dashboard.png\",\n    \"alt\": \"Kibana Dashboard\\\" width=\\\"550\"\n  }))), mdx(\"h2\", {\n    \"id\": \"log-shipping-challenge\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#log-shipping-challenge\"\n  })), \"Log shipping challenge\"), mdx(\"p\", null, \"The so\\xADlu\\xADtion pre\\xADsented here re\\xADlied on File\\xADbeat to ship log data to Logstash. How\\xADever, if you are fa\\xADmil\\xADiar with the Log4j frame\\xADwork you may be aware that there ex\\xADists a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Sock\\xADe\\xADtAp\\xADpen\\xADder\"), \" that al\\xADlows to write log events di\\xADrectly to a re\\xADmote server using a TCP con\\xADnec\\xADtion. Al\\xADthough in\\xADclud\\xADing the File\\xADbeat + Logstash com\\xADbi\\xADna\\xADtion  may sound an un\\xADnec\\xADes\\xADsary over\\xADhead to the log\\xADging pipeline, they pro\\xADvide a num\\xADber of ben\\xADe\\xADfits in com\\xADpar\\xADi\\xADson to the Log4j socket al\\xADter\\xADna\\xADtive:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The Sock\\xADe\\xADtAp\\xADpen\\xADder re\\xADlies on the spe\\xADcific se\\xADri\\xADal\\xADiza\\xADtion of Log4j\\u2019s \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Lo\\xADgEvent\"), \" ob\\xADjects, which is no an in\\xADter\\xADchange\\xADable for\\xADmat as JSON, which is used by the Beats so\\xADlu\\xADtion. Al\\xADthough there are \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://github.com/majikthys/log4j2-logstash-jsonevent-layout\"\n  }), \"at\\xADtempts\"), \" to out\\xADput the logs in a JSON for\\xADmat for Logstash, it doesn\\u2019t sup\\xADport mul\\xADti\\xADline logs, which re\\xADsults in mes\\xADsages being split into dif\\xADfer\\xADent events by Logstash. On the other hand, there is no of\\xADfi\\xADcial nor sta\\xADble \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://www.elastic.co/guide/en/logstash/current/input-plugins.html\"\n  }), \"input plugin\"), \" for Log4j ver\\xADsion 2.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"While en\\xADabling Log4j\\u2019s async log\\xADging mode in an ap\\xADpli\\xADca\\xADtion del\\xADe\\xADgates log\\xADging op\\xADer\\xADa\\xADtions to sep\\xADa\\xADrate threads, given their co\\xADex\\xADis\\xADtence in the same JVM there is still the risk of data loss in case of a sud\\xADden JVM ter\\xADmi\\xADna\\xADtion with\\xADout proper log chan\\xADnel clos\\xADing.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"File\\xADbeat is a data ship\\xADper de\\xADsigned to deal with many con\\xADstraints that arise in dis\\xADtrib\\xADuted en\\xADvi\\xADron\\xADments in a re\\xADli\\xADable man\\xADner, there\\xADfore it pro\\xADvides op\\xADtions to tai\\xADlor and scale this op\\xADer\\xADa\\xADtion to our needs: the pos\\xADsi\\xADbil\\xADity to load bal\\xADance be\\xADtween mul\\xADti\\xADple Logstash in\\xADstances, spec\\xADify the num\\xADber of si\\xADmul\\xADta\\xADne\\xADous File\\xADbeat work\\xADers that ship log files, and spec\\xADify a com\\xADpres\\xADsion level in order to re\\xADduce the con\\xADsumed band\\xADwidth. Be\\xADsides that, logs can be shipped in spe\\xADcific batch sizes, with max\\xADi\\xADmum amount of re\\xADtries, and spec\\xADi\\xADfy\\xADing a con\\xADnec\\xADtion time\\xADout.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Lastly, al\\xADthough File\\xADbeat can for\\xADward logs di\\xADrectly to Elas\\xADtic\\xADsearch, using Logstash as an in\\xADter\\xADme\\xADdi\\xADary of\\xADfers the pos\\xADsi\\xADbil\\xADity to col\\xADlect logs from di\\xADverse sources (e.g., sys\\xADtem met\\xADrics).\")), mdx(\"h2\", {\n    \"id\": \"demo\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#demo\"\n  })), \"Demo\"), mdx(\"p\", null, \"This post is ac\\xADcom\\xADpa\\xADnied by a demo based on the Vert.x Mi\\xADcroser\\xADvices \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://vertx-lab.dynamis-technologies.com/\"\n  }), \"work\\xADshop\"), \", where each of them is shipped in a Docker con\\xADtainer sim\\xADu\\xADlat\\xADing a dis\\xADtrib\\xADuted sys\\xADtem com\\xADposed of in\\xADde\\xADpen\\xADdent ad\\xADdress\\xADable nodes.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Also, the ELK stack is pro\\xADvi\\xADsioned using a pre\\xADcon\\xADfig\\xADured Docker image by \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/spujadas\"\n  }), \"S\\xE9bastien Pu\\xADjadas\"), \".\"), mdx(\"p\", null, \"Fol\\xADlow\\xADing the guide\\xADlines in this post, this demo con\\xADfig\\xADures each of the Mi\\xADcroser\\xADvices of the work\\xADshop, sets up a File\\xADbeat process on each of them to ship the logs to a cen\\xADtral con\\xADtainer host\\xADing the ELK stack.\"), mdx(\"h3\", {\n    \"id\": \"installation\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#installation\"\n  })), \"Installation\"), mdx(\"p\", null, \"In order to run this demo, it is nec\\xADes\\xADsary to have Docker in\\xADstalled, then pro\\xADceed with:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cloning or down\\xADload\\xADing the demo \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://github.com/ricardohmon/vertx-elk\"\n  }), \"repos\\xADi\\xADtory\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sep\\xADa\\xADrately, ob\\xADtain\\xADing the source code of the \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://github.com/ricardohmon/vertx-microservices-workshop/tree/elk-demo\"\n  }), \"branch\"), \" of the Mi\\xADcroser\\xADvices work\\xADshop adapted for this demo.\")), mdx(\"h3\", {\n    \"id\": \"building-the-example\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#building-the-example\"\n  })), \"Building the example\"), mdx(\"p\", null, \"The Docker im\\xADages be\\xADlong\\xADing to the Vert.x Mi\\xADcroser\\xADvices work\\xADshop need to be built sep\\xADa\\xADrately to this project be\\xADfore this project can be launched.\"), mdx(\"h3\", {\n    \"id\": \"building-the-vertx-microservices-workshop-docker-images\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#building-the-vertx-microservices-workshop-docker-images\"\n  })), \"Building the Vert.x Microservices workshop Docker images.\"), mdx(\"p\", null, \"Build the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"root\"), \" project and the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Trader Dash\\xADboard\"), \" fol\\xADlowed by each of the mod\\xADules con\\xADtained in the so\\xADlu\\xADtion folder. Issue the fol\\xADlow\\xADing com\\xADmands for this:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-bash\"\n  }), \"mvn clean install\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" trader-dashboard\\nmvn package docker:build\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" ../solution/audit-service\\nmvn package docker:build\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" ../compulsive-traders\\nmvn package docker:build\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" ../portfolio-service\\nmvn package docker:build\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" ../quote-generator/\\nmvn package docker:build\\n\")), mdx(\"h3\", {\n    \"id\": \"running-the-example\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#running-the-example\"\n  })), \"Running the example\"), mdx(\"p\", null, \"After build\\xADing the pre\\xADvi\\xADous im\\xADages, build and run the ex\\xADam\\xADple in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"vertx-elk\"), \" using the fol\\xADlow\\xADing com\\xADmand:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-ebnf\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attribute\"\n  }), \"docker-compose up\"), \"\\n\")), mdx(\"h3\", {\n    \"id\": \"the-demo\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#the-demo\"\n  })), \"The demo\"), mdx(\"p\", null, \"You can watch the demo in ac\\xADtion in the fol\\xADlow\\xADing screen\\xADcast:\"), mdx(\"div\", {\n    className: \"youtube-embed\"\n  }, mdx(\"iframe\", {\n    src: \"https://www.youtube.com/embed/8P-MgXSujes\",\n    frameBorder: \"0\",\n    allowFullScreen: true\n  })), mdx(\"h2\", {\n    \"id\": \"conclusion\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#conclusion\"\n  })), \"Conclusion\"), mdx(\"p\", null, \"The ELK stack is a pow\\xADer\\xADful set of tools that ease the ag\\xADgre\\xADga\\xADtion of logs com\\xADing from dis\\xADtrib\\xADuted ser\\xADvices into a cen\\xADtral server. Its main pil\\xADlar, Elas\\xADtic\\xADsearch, pro\\xADvides the in\\xADdex\\xADing and search ca\\xADpa\\xADbil\\xADi\\xADties of our log data. Also, it is ac\\xADcom\\xADpa\\xADnied by the con\\xADve\\xADnient input/out\\xADput com\\xADpo\\xADnents: Logstash, which can be flex\\xADi\\xADbly con\\xADfig\\xADured to ac\\xADcept dif\\xADfer\\xADent data sources; and Kibana, which can be cus\\xADtomized to present the in\\xADfor\\xADma\\xADtion in the most con\\xADve\\xADnient way.\"), mdx(\"p\", null, \"Logstash has been de\\xADsigned to work seam\\xADlessly with File\\xADbeat, the log ship\\xADper which rep\\xADre\\xADsents a ro\\xADbust so\\xADlu\\xADtion that can be adapted to our ap\\xADpli\\xADca\\xADtions with\\xADout hav\\xADing to make \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"sig\\xADnif\\xADi\\xADcant\"), \" changes to our ar\\xADchi\\xADtec\\xADture. In ad\\xADdi\\xADtion, Logstash can ac\\xADcept var\\xADied types of sources, fil\\xADter the data, and process it be\\xADfore de\\xADliv\\xADer\\xADing to Elas\\xADtic\\xADsearch. This flex\\xADi\\xADbil\\xADity comes with the price of hav\\xADing extra el\\xADe\\xADments in our log ag\\xADgre\\xADga\\xADtion pipeline, which can rep\\xADre\\xADsent an in\\xADcrease of pro\\xADcess\\xADing over\\xADhead or a point-\\u200Bof-failure. This ad\\xADdi\\xADtional over\\xADhead could be avoided if an ap\\xADpli\\xADca\\xADtion would be ca\\xADpa\\xADble of de\\xADliv\\xADer\\xADing its log out\\xADput di\\xADrectly to Elas\\xADtic\\xADsearch.\"), mdx(\"p\", null, \"Happy log\\xADging!\"));\n}\n\n;\nMDXContent.isMDXComponent = true;","renderedOutput":"<p>This post entry describes a solution to achieve centralized logging of Vert.x applications using the <a href=\"https://www.elastic.co/webinars/introduction-elk-stack\">ELK stack</a>, a set of tools including Logstash, Elasticsearch, and Kibana that are well known to work together seamlessly.</p><h2 id=\"preamble\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#preamble\"></a>Preamble</h2><p>This post was written in context of the project titled <a href=\"https://summerofcode.withgoogle.com/projects/#4858492141699072\">DevOps tooling for Vert.x applications</a>, one of the Vert.x projects taking place during the 2016 edition of <a href=\"https://summerofcode.withgoogle.com/about/\">Google Summer of Code</a>, a program that aims to bring together students with open source organizations, in order to help them to gain exposure to software development practices and real-world challenges.</p><h2 id=\"introduction\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#introduction\"></a>Introduction</h2><p>Centralized logging is an important topic while building a Microservices architecture and it is a step forward to adopting the DevOps culture. Having an overall solution partitioned into a set of services distributed across the Internet can represent a challenge when trying to monitor the log output of each of them, hence, a tool that helps to accomplish this results very helpful.</p><h2 id=\"overview\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#overview\"></a>Overview</h2><p>As shown in the diagram below, the general centralized logging solution comprises two main elements: the application server, which runs our Vert.x application; and a separate server, hosting the ELK stack. Both elements are linked by Filebeat, a highly configurable tool capable of shipping our application logs to the Logstash instance, i.e., our gateway to the ELK stack.</p><p><img src=\"/images/blog/centralized-logging-using-elk/elk-overview.svg\" alt=\"Overview of centralized logging with ELK\"/></p><h2 id=\"app-logging-configuration\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#app-logging-configuration\"></a>App logging configuration</h2><p>The approach described here is based on a Filebeat + Logstash configuration, that means first we need to make sure our app logs to a file, whose records will be shipped to Logstash by Filebeat. Luckily, Vert.x provides the means to <a href=\"/docs/vertx-core/java/#_logging\">configure</a> alternative logging frameworks (e.g., Log4j, Log4j2 and SLF4J) besides the default JUL logging. However, we can use Filebeat independently of the logging framework chosen.</p><h3 id=\"log4j-logging\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#log4j-logging\"></a>Log4j Logging</h3><p>The demo that accompanies this post relies on Log4j2 as the logging framework. We instructed Vert.x to use this framework following the <a href=\"/docs/vertx-core/java/#_logging\">guidelines</a> and we made sure our logging calls are made asynchronous, since we dont want them to block our application. For this purpose, we opted for the <code>AsyncAppender</code> and this was included in the Log4J configuration together with the log output format described in a XML configuration available in the applications <em>Resource</em> folder.</p><pre><code class=\"hljs language-xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Configuration</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Appenders</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">RollingFile</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;vertx_logs&quot;</span> <span class=\"hljs-attr\">append</span>=<span class=\"hljs-string\">&quot;true&quot;</span> <span class=\"hljs-attr\">fileName</span>=<span class=\"hljs-string\">&quot;/var/log/vertx.log&quot;</span> <span class=\"hljs-attr\">filePattern</span>=<span class=\"hljs-string\">&quot;/var/log/vertx/$${date:yyyy-MM}/vertx-%d{MM-dd-yyyy}-%i.log.gz&quot;</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">PatternLayout</span> <span class=\"hljs-attr\">pattern</span>=<span class=\"hljs-string\">&quot;%d{ISO8601} %-5p %c:%L - %m%n&quot;</span> /&gt;</span>\n    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">RollingFile</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Async</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;vertx_async&quot;</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">AppenderRef</span> <span class=\"hljs-attr\">ref</span>=<span class=\"hljs-string\">&quot;vertx_logs&quot;</span>/&gt;</span>\n    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Async</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Appenders</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Loggers</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Root</span> <span class=\"hljs-attr\">level</span>=<span class=\"hljs-string\">&quot;DEBUG&quot;</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">AppenderRef</span> <span class=\"hljs-attr\">ref</span>=<span class=\"hljs-string\">&quot;vertx_async&quot;</span> /&gt;</span>\n    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Root</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Loggers</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Configuration</span>&gt;</span>\n</code></pre><h3 id=\"filebeat-configuration\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#filebeat-configuration\"></a>Filebeat configuration</h3><p>Now that we have configured the log output of our Vert.x application to be stored in the file system, we delegate to Filebeat the task of forwarding the logs to the Logstash instance. Filebeat can be configured through a YAML file containing the logs output location and the pattern to interpret multiline logs (i.e., stack traces). Also, the Logstash output plugin is configured with the host location and a secure connection is enforced using the certificate from the machine hosting Logstash. We set the <code>document_type</code> to the type of instance that this log belongs to, which could later help us while indexing our logs inside Elasticsearch.</p><pre><code class=\"hljs language-yaml\"><span class=\"hljs-attr\">filebeat:</span>\n  <span class=\"hljs-attr\">prospectors:</span>\n    <span class=\"hljs-bullet\">-</span>\n      <span class=\"hljs-attr\">document_type:</span> <span class=\"hljs-string\">trader_dashboard</span>\n      <span class=\"hljs-attr\">paths:</span>\n        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">/var/log/vertx.log</span>\n      <span class=\"hljs-attr\">multiline:</span>\n        <span class=\"hljs-attr\">pattern:</span> <span class=\"hljs-string\">&quot;^[0-9]+&quot;</span>\n        <span class=\"hljs-attr\">negate:</span> <span class=\"hljs-literal\">true</span>\n        <span class=\"hljs-attr\">match:</span> <span class=\"hljs-string\">after</span>\n<span class=\"hljs-attr\">output:</span>\n  <span class=\"hljs-attr\">logstash:</span>\n    <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">true</span>\n    <span class=\"hljs-attr\">hosts:</span>\n      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">elk:5044</span>\n    <span class=\"hljs-attr\">timeout:</span> <span class=\"hljs-number\">15</span>\n    <span class=\"hljs-attr\">tls:</span>\n      <span class=\"hljs-attr\">insecure:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">certificate_authoritites:</span>\n        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">/etc/pki/tls/certs/logstash-beats.crt</span>\n</code></pre><h2 id=\"elk-configuration\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#elk-configuration\"></a>ELK configuration</h2><p>To take fully advantage of the ELK stack with respect to Vert.x and our app logs, we need to configure each of its individual components, namely Logstash, Elasticsearch and Kibana.</p><h3 id=\"logstash\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#logstash\"></a>Logstash</h3><p>Logstash is the component within the ELK stack that is in charge of aggregating the logs from each of the sources and forwarding them to the Elasticsearch instance.<br/>\n<!-- -->Configuring Logstash is straightforward with the help of the specific input and output plugins for Beats and Elasticsearch, respectively.\nIn the previous section we mentioned that Filebeat could be easily coupled with Logstash. Now, we see that this can be done by just specifying <code>Beat</code> as the input plugin and set the parameters needed to be reached by our shippers (listening port, ssl key and certificate location).</p><pre><code class=\"hljs language-bash\">input {\n  beats {\n    port =&gt; 5044\n    ssl =&gt; <span class=\"hljs-literal\">true</span>\n    ssl_certificate =&gt; <span class=\"hljs-string\">&quot;/etc/pki/tls/certs/logstash-beats.crt&quot;</span>\n    ssl_key =&gt; <span class=\"hljs-string\">&quot;/etc/pki/tls/private/logstash-beats.key&quot;</span>\n  }\n}\n</code></pre><p>Now that we are ready to receive logs from the app, we can use Logstash filtering capabilities to specify the format of our logs and extract the fields so they can be indexed more efficiently by Elasticsearch.<br/>\n<!-- -->The <code>grok</code> filtering plugin comes handy in this situation. This plugin allows to declare the logs format using predefined and customized patterns based in regular expressions allowing to declare new fields from the information extracted from each log line. In the following block, we instruct Logstash to recognize our Log4j pattern inside a <code>message</code> field, which contains the log message shipped by Filebeat. After that, the <code>date</code> filtering plugin parses the <code>timestamp</code> field extracted in the previous step and replaces it for the one set by Filebeat after reading the log output file.</p><pre><code class=\"hljs language-bash\">filter {\n  grok {\n    break_on_match =&gt; <span class=\"hljs-literal\">false</span>\n    match =&gt;  [ <span class=\"hljs-string\">&quot;message&quot;</span>, <span class=\"hljs-string\">&quot;%{LOG4J}&quot;</span>]\n  }\n  date{\n    match =&gt; [ <span class=\"hljs-string\">&quot;timestamp_string&quot;</span>, <span class=\"hljs-string\">&quot;ISO8601&quot;</span>]\n    remove_field =&gt; [ <span class=\"hljs-string\">&quot;timestamp_string&quot;</span> ]\n  }\n}\n</code></pre><p>The Log4j pattern is not included within the Logstash configuration, however, we can specify it using predefined data formats shipped with Logstash and adapt it to the specific log formats required in our application, as shown next.</p><pre><code class=\"hljs language-ruby\"><span class=\"hljs-comment\"># Pattern to match our Log4j format</span>\nSPACING (?<span class=\"hljs-symbol\">:</span>[\\s]+)\nLOGGER (?<span class=\"hljs-symbol\">:</span>[a-zA-Z$_][a-zA-Z$_0-<span class=\"hljs-number\">9</span>]*\\.)*[a-zA-Z$_][a-zA-Z$_0-<span class=\"hljs-number\">9</span>]*\nLINE <span class=\"hljs-string\">%{INT}</span>?\nLOG4J <span class=\"hljs-string\">%{TIMESTAMP_ISO8601:timestamp_string}</span> <span class=\"hljs-string\">%{LOGLEVEL:log_level}</span><span class=\"hljs-string\">%{SPACING}</span><span class=\"hljs-string\">%{LOGGER:logger_name}</span><span class=\"hljs-symbol\">:<span class=\"hljs-string\">%{LINE:loc_line}</span></span> - <span class=\"hljs-string\">%{JAVALOGMESSAGE:log_message}</span>\n</code></pre><p>Finally, we take a look at Logstashs output configuration. This simply points to our elasticsearch instance, instructs it to provide a list of all cluster nodes (<code>sniffing</code>), defines the name pattern for our indices, assigns the document type according to the metadata coming from Filebeat, and allows to define a custom index template for our data.</p><pre><code class=\"hljs language-puppet\"><span class=\"hljs-keyword\">output</span> {\n  elasticsearch {\n    <span class=\"hljs-attr\">hosts</span> =&gt; [<span class=\"hljs-string\">&quot;localhost&quot;</span>]\n    <span class=\"hljs-attr\">sniffing</span> =&gt; <span class=\"hljs-keyword\">true</span>\n    <span class=\"hljs-attr\">manage_template</span> =&gt; <span class=\"hljs-keyword\">true</span>\n    <span class=\"hljs-attr\">index</span> =&gt; <span class=\"hljs-string\">&quot;%{[@metadata][beat]}-%{+YYYY.MM.dd}&quot;</span>\n    <span class=\"hljs-attr\">document_type</span> =&gt; <span class=\"hljs-string\">&quot;%{[@metadata][type]}&quot;</span>\n    <span class=\"hljs-attr\">template</span> =&gt; <span class=\"hljs-string\">&quot;/etc/filebeat/vertx_app_filebeat.json&quot;</span>\n    <span class=\"hljs-attr\">template_overwrite</span> =&gt; <span class=\"hljs-keyword\">true</span>\n  }\n}\n</code></pre><h3 id=\"elasticsearch\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#elasticsearch\"></a>Elasticsearch</h3><p>Elasticsearch is the central component that enables the efficient indexing and real-time search capabilities of the stack. To take the most advantage of Elasticsearch, we can provide an indexing template of our incoming logs, which can help to optimize the data storage and match the queries issued by Kibana at a later point.<br/>\n<!-- -->In the example below, we see an index template that would be applied to any index matching the pattern <code>filebeat-*</code>. Additionally, we declare our new log fields <code>type</code>, <code>host</code>, <code>log_level</code>, <code>logger_name</code>, and <code>log_message</code>, which are set as <code>not_analyzed</code> except for the last two that are set as <code>analyzed</code> allowing to perform queries based on regular expressions and not restricted to query the full text.</p><pre><code class=\"hljs language-json\">{\n  <span class=\"hljs-attr\">&quot;mappings&quot;</span>: {\n    <span class=\"hljs-attr\">&quot;_default_&quot;</span>: {\n      <span class=\"hljs-attr\">&quot;_all&quot;</span>: {\n        <span class=\"hljs-attr\">&quot;enabled&quot;</span>: <span class=\"hljs-literal\">true</span>,\n        <span class=\"hljs-attr\">&quot;norms&quot;</span>: {\n          <span class=\"hljs-attr\">&quot;enabled&quot;</span>: <span class=\"hljs-literal\">false</span>\n        }\n      },\n      <span class=\"hljs-attr\">&quot;dynamic_templates&quot;</span>: [\n        {\n          <span class=\"hljs-attr\">&quot;template1&quot;</span>: {\n            <span class=\"hljs-attr\">&quot;mapping&quot;</span>: {\n              <span class=\"hljs-attr\">&quot;doc_values&quot;</span>: <span class=\"hljs-literal\">true</span>,\n              <span class=\"hljs-attr\">&quot;ignore_above&quot;</span>: <span class=\"hljs-number\">1024</span>,\n              <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;not_analyzed&quot;</span>,\n              <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;{dynamic_type}&quot;</span>\n            },\n            <span class=\"hljs-attr\">&quot;match&quot;</span>: <span class=\"hljs-string\">&quot;*&quot;</span>\n          }\n        }\n      ],\n      <span class=\"hljs-attr\">&quot;properties&quot;</span>: {\n        <span class=\"hljs-attr\">&quot;@timestamp&quot;</span>: {\n          <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;date&quot;</span>\n        },\n        <span class=\"hljs-attr\">&quot;offset&quot;</span>: {\n          <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;long&quot;</span>,\n          <span class=\"hljs-attr\">&quot;doc_values&quot;</span>: <span class=\"hljs-string\">&quot;true&quot;</span>\n        },\n        <span class=\"hljs-attr\">&quot;type&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;not_analyzed&quot;</span> },\n        <span class=\"hljs-attr\">&quot;host&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;not_analyzed&quot;</span> },\n        <span class=\"hljs-attr\">&quot;log_level&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;not_analyzed&quot;</span> },\n        <span class=\"hljs-attr\">&quot;logger_name&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;analyzed&quot;</span> },\n        <span class=\"hljs-attr\">&quot;log_message&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;analyzed&quot;</span> }\n      }\n    }\n  },\n  <span class=\"hljs-attr\">&quot;settings&quot;</span>: {\n    <span class=\"hljs-attr\">&quot;index.refresh_interval&quot;</span>: <span class=\"hljs-string\">&quot;5s&quot;</span>\n  },\n  <span class=\"hljs-attr\">&quot;template&quot;</span>: <span class=\"hljs-string\">&quot;filebeat-*&quot;</span>\n}\n</code></pre><h3 id=\"kibana\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#kibana\"></a>Kibana</h3><p>Although we could fetch all our logs from Elasticsearch through its API, Kibana is a powerful tool that allows a more friendly query and visualization.\nBesides the option to query our data through the available indexed field names and search boxes allowing typing specific queries, Kibana allows creating our own <em>Visualizations</em> and <em>Dashboards</em>. Combined, they represent a powerful way to display data and gain insight in a customized manner.\nThe accompanied demo ships with a couple of sample dashboards and visualizations that take advantage of the log fields that we specified in our index template and throw valuable insight. This includes: visualizing the number of log messages received by ELK, observe the proportion of messages that each log source produces, and directly find out the sources of error logs.</p><p><img src=\"/images/blog/centralized-logging-using-elk/kibana-dashboard.png\" alt=\"Kibana Dashboard&quot; width=&quot;550\"/></p><h2 id=\"log-shipping-challenge\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#log-shipping-challenge\"></a>Log shipping challenge</h2><p>The solution presented here relied on Filebeat to ship log data to Logstash. However, if you are familiar with the Log4j framework you may be aware that there exists a <em>SocketAppender</em> that allows to write log events directly to a remote server using a TCP connection. Although including the Filebeat + Logstash combination  may sound an unnecessary overhead to the logging pipeline, they provide a number of benefits in comparison to the Log4j socket alternative:</p><ul><li>The SocketAppender relies on the specific serialization of Log4js <em>LogEvent</em> objects, which is no an interchangeable format as JSON, which is used by the Beats solution. Although there are <a href=\"https://github.com/majikthys/log4j2-logstash-jsonevent-layout\">attempts</a> to output the logs in a JSON format for Logstash, it doesnt support multiline logs, which results in messages being split into different events by Logstash. On the other hand, there is no official nor stable <a href=\"https://www.elastic.co/guide/en/logstash/current/input-plugins.html\">input plugin</a> for Log4j version 2.</li><li>While enabling Log4js async logging mode in an application delegates logging operations to separate threads, given their coexistence in the same JVM there is still the risk of data loss in case of a sudden JVM termination without proper log channel closing.</li><li>Filebeat is a data shipper designed to deal with many constraints that arise in distributed environments in a reliable manner, therefore it provides options to tailor and scale this operation to our needs: the possibility to load balance between multiple Logstash instances, specify the number of simultaneous Filebeat workers that ship log files, and specify a compression level in order to reduce the consumed bandwidth. Besides that, logs can be shipped in specific batch sizes, with maximum amount of retries, and specifying a connection timeout.</li><li>Lastly, although Filebeat can forward logs directly to Elasticsearch, using Logstash as an intermediary offers the possibility to collect logs from diverse sources (e.g., system metrics).</li></ul><h2 id=\"demo\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#demo\"></a>Demo</h2><p>This post is accompanied by a demo based on the Vert.x Microservices <a href=\"http://vertx-lab.dynamis-technologies.com/\">workshop</a>, where each of them is shipped in a Docker container simulating a distributed system composed of independent addressable nodes.<br/>\n<!-- -->Also, the ELK stack is provisioned using a preconfigured Docker image by <a href=\"https://github.com/spujadas\">Sbastien Pujadas</a>.</p><p>Following the guidelines in this post, this demo configures each of the Microservices of the workshop, sets up a Filebeat process on each of them to ship the logs to a central container hosting the ELK stack.</p><h3 id=\"installation\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#installation\"></a>Installation</h3><p>In order to run this demo, it is necessary to have Docker installed, then proceed with:</p><ul><li>Cloning or downloading the demo <a href=\"https://github.com/ricardohmon/vertx-elk\">repository</a>.</li><li>Separately, obtaining the source code of the <a href=\"https://github.com/ricardohmon/vertx-microservices-workshop/tree/elk-demo\">branch</a> of the Microservices workshop adapted for this demo.</li></ul><h3 id=\"building-the-example\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#building-the-example\"></a>Building the example</h3><p>The Docker images belonging to the Vert.x Microservices workshop need to be built separately to this project before this project can be launched.</p><h3 id=\"building-the-vertx-microservices-workshop-docker-images\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#building-the-vertx-microservices-workshop-docker-images\"></a>Building the Vert.x Microservices workshop Docker images.</h3><p>Build the <em>root</em> project and the <em>Trader Dashboard</em> followed by each of the modules contained in the solution folder. Issue the following commands for this:</p><pre><code class=\"hljs language-bash\">mvn clean install\n<span class=\"hljs-built_in\">cd</span> trader-dashboard\nmvn package docker:build\n<span class=\"hljs-built_in\">cd</span> ../solution/audit-service\nmvn package docker:build\n<span class=\"hljs-built_in\">cd</span> ../compulsive-traders\nmvn package docker:build\n<span class=\"hljs-built_in\">cd</span> ../portfolio-service\nmvn package docker:build\n<span class=\"hljs-built_in\">cd</span> ../quote-generator/\nmvn package docker:build\n</code></pre><h3 id=\"running-the-example\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#running-the-example\"></a>Running the example</h3><p>After building the previous images, build and run the example in <code>vertx-elk</code> using the following command:</p><pre><code class=\"hljs language-ebnf\"><span class=\"hljs-attribute\">docker-compose up</span>\n</code></pre><h3 id=\"the-demo\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#the-demo\"></a>The demo</h3><p>You can watch the demo in action in the following screencast:</p><div class=\"youtube-embed\"><iframe src=\"https://www.youtube.com/embed/8P-MgXSujes\" frameBorder=\"0\" allowfullscreen=\"\"></iframe></div><h2 id=\"conclusion\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#conclusion\"></a>Conclusion</h2><p>The ELK stack is a powerful set of tools that ease the aggregation of logs coming from distributed services into a central server. Its main pillar, Elasticsearch, provides the indexing and search capabilities of our log data. Also, it is accompanied by the convenient input/output components: Logstash, which can be flexibly configured to accept different data sources; and Kibana, which can be customized to present the information in the most convenient way.</p><p>Logstash has been designed to work seamlessly with Filebeat, the log shipper which represents a robust solution that can be adapted to our applications without having to make <em>significant</em> changes to our architecture. In addition, Logstash can accept varied types of sources, filter the data, and process it before delivering to Elasticsearch. This flexibility comes with the price of having extra elements in our log aggregation pipeline, which can represent an increase of processing overhead or a point-of-failure. This additional overhead could be avoided if an application would be capable of delivering its log output directly to Elasticsearch.</p><p>Happy logging!</p>","scope":{}}},"prevPost":{"meta":{"title":"Vert.x 3.3.3 is released!","category":"releases","authors":[{"name":"Clement Escoffier","github_id":"cescoffier"}],"summary":"We have just released Vert.x 3.3.3, a bug fix release of Vert.x 3.3.x."},"date":"2016-09-12","slug":"vert-x-3-3-3-is-released"},"nextPost":{"meta":{"title":"Vert.x Blueprint Tutorials","category":"guides","authors":[{"name":"Eric Zhao","github_id":"sczyh30"}],"summary":"The Vert.x Blueprint project aims to provide guidelines to Vert.x users to implement various applications such as message-based applications and microservices."},"date":"2016-09-01","slug":"vert-x-blueprint-tutorials"},"relatedPosts":[{"meta":{"title":"Getting started with new fabric8 Vert.x Maven Plugin","category":"guides","authors":[{"name":"Kamesh Sampath","github_id":"kameshsampath"}],"summary":"The all new fabric8 Vert.x Maven Plugin allows you to setup, package, run, start, stop and redeploy easily with a very little configuration resulting in a less verbose pom.xml."},"date":"2016-12-07","slug":"getting-started-with-new-fabric8-vert-x-maven-plugin"},{"meta":{"title":"Vert.x featuring Continuous Delivery with Jenkins and Ansible","category":"guides","authors":[{"name":"Ricardo Hernandez","github_id":"ricardohmon"}],"summary":"This blog entry describes an approach to adopt Continuous Delivery for Vert.x applications using Jenkins and Ansible by taking advantage of the Jenkins Job DSL and Ansible plugins."},"date":"2016-09-28","slug":"vert-x-featuring-continuous-delivery-with-jenkins-and-ansible"},{"meta":{"title":"Unit and Integration Tests","category":"guides","authors":[{"name":"Clement Escoffier","github_id":"cescoffier"}],"summary":"Lets refresh our mind about what we developed so far in the introduction to vert.x series. We forgot an important task. We didnt test the API."},"date":"2015-08-03","slug":"unit-and-integration-tests"}]},"__N_SSG":true}